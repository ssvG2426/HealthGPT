{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================== CELL 1: DEPENDENCIES ==========================\nimport subprocess\nimport sys\n\nprint('ðŸ”§ Installing dependencies...')\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"pyarrow\"], capture_output=True, check=False)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyarrow==15.0.2\", \"keybert\", \"rank-bm25\", \"faiss-cpu\", \"sacremoses\"], check=True)\nprint('âœ… Dependencies installed. RESTART kernel and run Cell 2.')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== CELL 2: IMPORTS & SETUP =====================\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport re\nimport json\nimport time\nimport pickle\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple\n\nimport numpy as np\nimport torch\nimport faiss\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom rank_bm25 import BM25Okapi\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ðŸ”§ Using device: {device}\")\n\n# ============================================================================\n# CONFIGURATION FOR GENERAL MEDICAL DOMAIN\n# ============================================================================\n\n@dataclass\nclass DomainConfig:\n    name: str = \"general_medical\"\n    dataset_name: str = \"lavita/ChatDoctor-HealthCareMagic-100k\"\n    dataset_split: str = \"train\"\n    chunk_window: int = 3\n    chunk_stride: int = 1\n    embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n\nconfig = DomainConfig()\n\nprint(f\"ðŸ“‹ Building index for: {config.name}\")\nprint(f\"ðŸ“¦ Dataset: {config.dataset_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:44:23.425275Z","iopub.execute_input":"2025-11-01T18:44:23.426107Z","iopub.status.idle":"2025-11-01T18:44:23.435237Z","shell.execute_reply.started":"2025-11-01T18:44:23.426068Z","shell.execute_reply":"2025-11-01T18:44:23.434358Z"}},"outputs":[{"name":"stdout","text":"ðŸ”§ Using device: cuda\nðŸ“‹ Building index for: general_medical\nðŸ“¦ Dataset: lavita/ChatDoctor-HealthCareMagic-100k\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ===================== CELL 3: DATASET LOADING =====================\n\ndef extract_qa_pairs(dataset) -> list:\n    \"\"\"Extract Q&A pairs from ChatDoctor-HealthCareMagic dataset.\"\"\"\n    qa_data = []\n    \n    for idx, row in enumerate(dataset):\n        try:\n            # ChatDoctor structure: 'instruction' and 'output'\n            if 'instruction' in row and 'output' in row:\n                question = str(row['instruction']).strip()\n                answer = str(row['output']).strip()\n                \n                if question and answer and len(answer) > 20:\n                    qa_data.append({\n                        \"question\": question,\n                        \"answer\": answer,\n                        \"source_id\": idx\n                    })\n            \n            # Alternative structure: 'input' and 'output'\n            elif 'input' in row and 'output' in row:\n                question = str(row['input']).strip()\n                answer = str(row['output']).strip()\n                \n                if question and answer and len(answer) > 20:\n                    qa_data.append({\n                        \"question\": question,\n                        \"answer\": answer,\n                        \"source_id\": idx\n                    })\n            \n            # Generic Q&A structure\n            elif 'question' in row and 'answer' in row:\n                question = str(row['question']).strip()\n                answer = str(row['answer']).strip()\n                \n                if question and answer and len(answer) > 20:\n                    qa_data.append({\n                        \"question\": question,\n                        \"answer\": answer,\n                        \"source_id\": idx\n                    })\n                    \n        except Exception as e:\n            if idx < 3:\n                print(f\"âš ï¸ Row {idx} skipped: {e}\")\n            continue\n    \n    return qa_data\n\n# Load dataset\nprint(f\"ðŸ“¥ Loading {config.dataset_name}...\")\ndataset = load_dataset(config.dataset_name, split=config.dataset_split)\nprint(f\"âœ… Loaded {len(dataset)} rows\")\n\n# Print sample row to verify structure\nprint(f\"\\nðŸ“‹ Sample row structure:\")\nprint(f\"Keys: {list(dataset[0].keys())}\")\nprint(f\"Sample: {dataset[0]}\")\n\n# Extract Q&A pairs\nprint(f\"\\nðŸ” Extracting Q&A pairs...\")\nqa_data = extract_qa_pairs(dataset)\nprint(f\"âœ… Extracted {len(qa_data)} Q&A pairs\")\n\nif len(qa_data) < 1000:\n    print(f\"âš ï¸ WARNING: Only {len(qa_data)} pairs extracted from 100k dataset!\")\n    print(f\"Sample extracted pair:\")\n    if qa_data:\n        print(f\"Q: {qa_data[0]['question'][:100]}...\")\n        print(f\"A: {qa_data[0]['answer'][:100]}...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:44:26.426223Z","iopub.execute_input":"2025-11-01T18:44:26.427031Z","iopub.status.idle":"2025-11-01T18:44:33.065452Z","shell.execute_reply.started":"2025-11-01T18:44:26.427005Z","shell.execute_reply":"2025-11-01T18:44:33.064639Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¥ Loading lavita/ChatDoctor-HealthCareMagic-100k...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/542 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b27b26cde9c45aa80665cf83496330e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-5e7cb295b9cff0(â€¦):   0%|          | 0.00/70.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582fc4f17ff04285b62471d351e87a80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/112165 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae5b3f1b8ed74b95b6793f01fba021bc"}},"metadata":{}},{"name":"stdout","text":"âœ… Loaded 112165 rows\n\nðŸ“‹ Sample row structure:\nKeys: ['instruction', 'input', 'output']\nSample: {'instruction': \"If you are a doctor, please answer the medical questions based on the patient's description.\", 'input': 'I woke up this morning feeling the whole room is spinning when i was sitting down. I went to the bathroom walking unsteadily, as i tried to focus i feel nauseous. I try to vomit but it wont come out.. After taking panadol and sleep for few hours, i still feel the same.. By the way, if i lay down or sit down, my head do not spin, only when i want to move around then i feel the whole world is spinning.. And it is normal stomach discomfort at the same time? Earlier after i relieved myself, the spinning lessen so i am not sure whether its connected or coincidences.. Thank you doc!', 'output': 'Hi, Thank you for posting your query. The most likely cause for your symptoms is benign paroxysmal positional vertigo (BPPV), a type of peripheral vertigo. In this condition, the most common symptom is dizziness or giddiness, which is made worse with movements. Accompanying nausea and vomiting are common. The condition is due to problem in the ear, and improves in a few days on own. Betahistine tablets would help relieve your symptoms. Doing vestibular rehabilitation or adaptation exercises would prevent the recurrence of these symptoms. An ENT evaluation would also help. I hope it helps. Best wishes, Chat Doctor.'}\n\nðŸ” Extracting Q&A pairs...\nâœ… Extracted 111885 Q&A pairs\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===================== CELL 4: TEXT CHUNKING =====================\n\ndef create_chunks(data: List[Dict], window: int = 3, stride: int = 1) -> List[Dict]:\n    \"\"\"Create sentence-level chunks from answers.\"\"\"\n    chunks = []\n    \n    for item in data:\n        text = item.get(\"answer\", \"\")\n        if not text or len(text) < 50:\n            continue\n        \n        sentences = sent_tokenize(text)\n        if not sentences:\n            continue\n        \n        # If answer is short, keep as one chunk\n        if len(sentences) <= window:\n            chunks.append({\n                \"chunk\": \" \".join(sentences),\n                \"source_idx\": item.get(\"source_id\", -1),\n                \"chunk_id\": len(chunks)\n            })\n            continue\n        \n        # Create overlapping chunks\n        for i in range(0, max(1, len(sentences) - window + 1), stride):\n            chunks.append({\n                \"chunk\": \" \".join(sentences[i:i + window]),\n                \"source_idx\": item.get(\"source_id\", -1),\n                \"chunk_id\": len(chunks)\n            })\n    \n    return chunks\n\n# Create chunks\nprint(f\"ðŸ”ª Creating chunks (window={config.chunk_window}, stride={config.chunk_stride})...\")\nchunks = create_chunks(qa_data, window=config.chunk_window, stride=config.chunk_stride)\nprint(f\"âœ… Created {len(chunks)} chunks\")\n\n# Sample chunks\nprint(\"\\nðŸ“ Sample chunks:\")\nfor i, chunk in enumerate(chunks[:3]):\n    print(f\"{i+1}. {chunk['chunk'][:150]}...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:44:33.066672Z","iopub.execute_input":"2025-11-01T18:44:33.066903Z","iopub.status.idle":"2025-11-01T18:44:48.705624Z","shell.execute_reply.started":"2025-11-01T18:44:33.066886Z","shell.execute_reply":"2025-11-01T18:44:48.704715Z"}},"outputs":[{"name":"stdout","text":"ðŸ”ª Creating chunks (window=3, stride=1)...\nâœ… Created 710919 chunks\n\nðŸ“ Sample chunks:\n1. Hi, Thank you for posting your query. The most likely cause for your symptoms is benign paroxysmal positional vertigo (BPPV), a type of peripheral ver...\n2. The most likely cause for your symptoms is benign paroxysmal positional vertigo (BPPV), a type of peripheral vertigo. In this condition, the most comm...\n3. In this condition, the most common symptom is dizziness or giddiness, which is made worse with movements. Accompanying nausea and vomiting are common....\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ===================== CELL 5: BUILD FAISS INDEX =====================\n\n# Load embedder\nprint(f\"ðŸ“¦ Loading embedder: {config.embed_model}\")\nembedder = SentenceTransformer(config.embed_model, device=device)\nprint(f\"âœ… Embedder loaded\")\n\n# Extract chunk texts\nid2doc = [chunk[\"chunk\"] for chunk in chunks]\nprint(f\"ðŸ“Š Encoding {len(id2doc)} chunks...\")\n\n# Create embeddings\nembeddings = embedder.encode(\n    id2doc,\n    normalize_embeddings=True,\n    show_progress_bar=True,\n    batch_size=32,\n    convert_to_numpy=True\n).astype('float32')\n\nprint(f\"âœ… Embeddings shape: {embeddings.shape}\")\n\n# Build FAISS index\ndim = embeddings.shape[1]\nindex = faiss.IndexFlatIP(dim)\nindex.add(embeddings)\n\nprint(f\"âœ… FAISS index built: {index.ntotal} vectors, dimension {dim}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:44:48.706590Z","iopub.execute_input":"2025-11-01T18:44:48.706870Z","iopub.status.idle":"2025-11-01T18:52:22.949102Z","shell.execute_reply.started":"2025-11-01T18:44:48.706847Z","shell.execute_reply":"2025-11-01T18:52:22.948280Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¦ Loading embedder: sentence-transformers/all-MiniLM-L6-v2\nâœ… Embedder loaded\nðŸ“Š Encoding 710919 chunks...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/22217 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e5a42a145364c3e852b45572b58ca9b"}},"metadata":{}},{"name":"stdout","text":"âœ… Embeddings shape: (710919, 384)\nâœ… FAISS index built: 710919 vectors, dimension 384\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ===================== CELL 6: BUILD BM25 INDEX =====================\n\n# Tokenize for BM25\nprint(f\"ðŸ”¨ Building BM25 index...\")\nbm25_corpus = [word_tokenize(doc.lower()) for doc in id2doc]\nbm25 = BM25Okapi(bm25_corpus)\nprint(f\"âœ… BM25 index built\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:52:22.951034Z","iopub.execute_input":"2025-11-01T18:52:22.951281Z","iopub.status.idle":"2025-11-01T18:55:45.840618Z","shell.execute_reply.started":"2025-11-01T18:52:22.951251Z","shell.execute_reply":"2025-11-01T18:55:45.839897Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¨ Building BM25 index...\nâœ… BM25 index built\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ===================== CELL 7: SAVE INDEXES =====================\n\n# File names\nindex_file = f\"{config.name}_faiss.index\"\nid2doc_file = f\"{config.name}_id2doc.pkl\"\nmetadata_file = f\"{config.name}_metadata.json\"\n\n# Save FAISS index\nprint(f\"ðŸ’¾ Saving FAISS index to {index_file}...\")\nfaiss.write_index(index, index_file)\n\n# Save id2doc mapping\nprint(f\"ðŸ’¾ Saving id2doc to {id2doc_file}...\")\nwith open(id2doc_file, \"wb\") as f:\n    pickle.dump(id2doc, f)\n\n# Save metadata\nmetadata = {\n    \"created_at\": time.time(),\n    \"domain\": config.name,\n    \"dataset\": config.dataset_name,\n    \"n_vectors\": int(index.ntotal),\n    \"embedding_dim\": dim,\n    \"chunk_window\": config.chunk_window,\n    \"chunk_stride\": config.chunk_stride,\n    \"embed_model\": config.embed_model\n}\n\nprint(f\"ðŸ’¾ Saving metadata to {metadata_file}...\")\nwith open(metadata_file, \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ… INDEX BUILDING COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"ðŸ“ Files created:\")\nprint(f\"  - {index_file}\")\nprint(f\"  - {id2doc_file}\")\nprint(f\"  - {metadata_file}\")\nprint(f\"\\nðŸ“Š Statistics:\")\nprint(f\"  - Total vectors: {index.ntotal}\")\nprint(f\"  - Embedding dimension: {dim}\")\nprint(f\"  - Source Q&A pairs: {len(qa_data)}\")\nprint(f\"  - Chunks created: {len(chunks)}\")\nprint(\"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:55:45.841414Z","iopub.execute_input":"2025-11-01T18:55:45.841655Z","iopub.status.idle":"2025-11-01T18:55:47.003173Z","shell.execute_reply.started":"2025-11-01T18:55:45.841630Z","shell.execute_reply":"2025-11-01T18:55:47.002376Z"}},"outputs":[{"name":"stdout","text":"ðŸ’¾ Saving FAISS index to general_medical_faiss.index...\nðŸ’¾ Saving id2doc to general_medical_id2doc.pkl...\nðŸ’¾ Saving metadata to general_medical_metadata.json...\n\n================================================================================\nâœ… INDEX BUILDING COMPLETE!\n================================================================================\nðŸ“ Files created:\n  - general_medical_faiss.index\n  - general_medical_id2doc.pkl\n  - general_medical_metadata.json\n\nðŸ“Š Statistics:\n  - Total vectors: 710919\n  - Embedding dimension: 384\n  - Source Q&A pairs: 111885\n  - Chunks created: 710919\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ===================== CELL 8: VERIFY INDEX (OPTIONAL) =====================\n\ndef test_retrieval(query: str, top_k: int = 5):\n    \"\"\"Test the built index with a sample query.\"\"\"\n    print(f\"\\nðŸ” Testing query: '{query}'\")\n    \n    # Embed query\n    query_emb = embedder.encode([query], normalize_embeddings=True, convert_to_numpy=True).astype('float32')\n    \n    # Search FAISS\n    D, I = index.search(query_emb, top_k)\n    \n    print(f\"\\nðŸ“‹ Top {top_k} results:\")\n    for i, (idx, score) in enumerate(zip(I[0], D[0]), 1):\n        print(f\"\\n{i}. Score: {score:.4f}\")\n        print(f\"   {id2doc[idx][:200]}...\")\n\n# Test queries\ntest_queries = [\n    \"I feel anxious and depressed\",\n    \"How to deal with stress?\",\n    \"I'm having panic attacks\"\n]\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ðŸ§ª TESTING INDEX\")\nprint(\"=\"*80)\n\nfor query in test_queries:\n    test_retrieval(query, top_k=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:55:47.004079Z","iopub.execute_input":"2025-11-01T18:55:47.004360Z","iopub.status.idle":"2025-11-01T18:55:47.352764Z","shell.execute_reply.started":"2025-11-01T18:55:47.004343Z","shell.execute_reply":"2025-11-01T18:55:47.351992Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nðŸ§ª TESTING INDEX\n================================================================================\n\nðŸ” Testing query: 'I feel anxious and depressed'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aaca6f7c510482fa7c7a687c930ef73"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.7162\n   You should find an answer. Are you anxious? Are you depressed?...\n\n2. Score: 0.6747\n   I suggest you not to worry much. I can see your problem. You know you are depressed, and you have anxiety disorder....\n\n3. Score: 0.6744\n   You should understand that you are not depressed. You are dissatisfied, disappointed. Furthermore, you are anxious due to that....\n\nðŸ” Testing query: 'How to deal with stress?'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0004a3ba8964da59fa4eba62a619636"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.7682\n   Consume nutritious food. Lead a stress-free life. I hope my answer will help you....\n\n2. Score: 0.7609\n   Don't stress yourself much, take adequate nutritious food on time, as it is the requirement of the body. Focus and concentrate on your career. If you have not studied much, focus on your hobbies and t...\n\n3. Score: 0.7593\n   Talk to Someone. Keep a Stress Diary. Take Control....\n\nðŸ” Testing query: 'I'm having panic attacks'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bdd6b24697544d9aeee9f96f5364d9f"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“‹ Top 3 results:\n\n1. Score: 0.7043\n   I have gone through your question in detail and I can understand what you are going through. It seems you are having panic attacks, and you certainly need treatment for the same. There are two types o...\n\n2. Score: 0.7021\n   If you have panic attacks then you should consult psychiatrist and take treatment accordingly. Hope I have answered your question, if you have doubt then I will be happy to answer. Thanks for using Ch...\n\n3. Score: 0.6996\n   Moreover, you have history of panic attacks. In addition, your investigations has come out to be normal. You should consult a psychiatrist for complete evaluation and initiating treatment....\n","output_type":"stream"}],"execution_count":14}]}